{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFLiEonUv5cv"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import PIL.ImageOps    \n",
        "from torchvision import models, transforms\n",
        "import logging\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchvision.utils\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "import shutil\n",
        "import os\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8uJHLsgK-l-"
      },
      "outputs": [],
      "source": [
        "# Plotting data\n",
        "def show_plot(iteration,loss):\n",
        "    plt.plot(iteration,loss)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr3WDlcSbSNJ"
      },
      "source": [
        "Bedoeling hieronder is dat ie uit de dataset random een pair pakt (img0 en img1) en eentje pakt die niet tot dezelfde class behoort\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yTBjtWl4jrV"
      },
      "outputs": [],
      "source": [
        "#dataloader for getting triplets from dataset\n",
        "class SiameseNetworkDataset(Dataset):\n",
        "    def __init__(self,imageFolderDataset,transform=None):\n",
        "        self.imageFolderDataset = imageFolderDataset    \n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self,index):\n",
        "        #img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "        #search untille requirements are met (same class)\n",
        "        while True:\n",
        "          img1_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "          if img0_tuple[1] == img1_tuple[1]:\n",
        "            break\n",
        "        while True:\n",
        "          #search untill they arent the same class\n",
        "          img2_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "          if img0_tuple[1] != img2_tuple[1]:\n",
        "            break\n",
        "        while True:\n",
        "          img3_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "          if (img3_tuple[1] != img1_tuple[1]) and (img3_tuple[1] != img2_tuple[1]):\n",
        "            break\n",
        "        while True:\n",
        "          img4_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "          if (img4_tuple[1] != img1_tuple[1]) and (img4_tuple[1] != img2_tuple[1]) and (img4_tuple[1] != img3_tuple[1]):\n",
        "            break\n",
        "        \n",
        "        img0 = Image.open(img0_tuple[0])\n",
        "        img1 = Image.open(img1_tuple[0])\n",
        "        img2 = Image.open(img2_tuple[0])\n",
        "        img3 = Image.open(img3_tuple[0])\n",
        "        img4 = Image.open(img4_tuple[0])\n",
        "\n",
        "      \n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "            img3 = self.transform(img3)\n",
        "            img4 = self.transform(img4)\n",
        "\n",
        "\n",
        "        return img0, img1, img2, img3, img4\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.imageFolderDataset.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXeqpMD-JMxI",
        "outputId": "b359e9e0-14c1-4d18-8113-7f52c24a0999"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_gu-w-w1T8x"
      },
      "outputs": [],
      "source": [
        "# Resize the images and transform to tensors\n",
        "transformation = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(), transforms.Normalize(mean=[0.486, 0.459, 0.408],\n",
        "                                 std=[0.229, 0.224, 0.225]),transforms.RandomHorizontalFlip(),\n",
        "                                    \n",
        "                                    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAqFAwBmJRDI"
      },
      "outputs": [],
      "source": [
        "folder_dataset = datasets.ImageFolder(root=\"/content/drive/MyDrive/Person_reID_baseline_pytorch/Market-1501-v15.09.15/pytorch/train_all\")\n",
        "folder_validationset = datasets.ImageFolder(root=\"//content/drive/MyDrive/Person_reID_baseline_pytorch/Market-1501-v15.09.15/pytorch/valid\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BLgqJQN1ylJ"
      },
      "outputs": [],
      "source": [
        "train = SiameseNetworkDataset(imageFolderDataset=folder_dataset,\n",
        "                                        transform=transformation)\n",
        "\n",
        "valid = SiameseNetworkDataset(imageFolderDataset=folder_validationset,\n",
        "                                        transform=transformation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYsnMoWyIn7s"
      },
      "outputs": [],
      "source": [
        "trainloader = DataLoader(train, batch_size=32, num_workers=0, shuffle=True)\n",
        "validloader = DataLoader(valid, batch_size=32, num_workers=0, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7XL7pCac-TW"
      },
      "outputs": [],
      "source": [
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtceyuf7a1X5"
      },
      "outputs": [],
      "source": [
        "class quintuplet(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(quintuplet, self).__init__()\n",
        "        self.net = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights)\n",
        "\n",
        "\n",
        "    def forward(self, input1, input2, input3, input4, input5):\n",
        "\n",
        "        output1 = self.net(input1)\n",
        "        output2 = self.net(input2)\n",
        "        output3 = self.net(input3)\n",
        "        output4 = self.net(input4)\n",
        "        output5 = self.net(input5)\n",
        "\n",
        "        return output1, output2, output3, output4, output5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rax388M10tm6"
      },
      "outputs": [],
      "source": [
        "# define the tripletLoss function\n",
        "class Quintupletloss(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Quintuplet loss function.\n",
        "    Takes 5 data input: one anchor, one positive and two negative examples. The negative examples needs not to be matching the anchor, the positive and each other.\n",
        "    \"\"\"\n",
        "    def __init__(self, margin1=1, margin2=0.25, margin3=0.25):\n",
        "        super(Quintupletloss, self).__init__()\n",
        "        self.margin1 = margin1\n",
        "        self.margin2 = margin2\n",
        "        self.margin3 = margin3\n",
        "\n",
        "    def forward(self, anchor, positive, negative1, negative2, negative3):\n",
        "\n",
        "        squarred_distance_pos = (anchor - positive).pow(2).sum(1)\n",
        "        squarred_distance_neg = (anchor - negative1).pow(2).sum(1)\n",
        "        squarred_distance_neg_b = (negative1 - negative2).pow(2).sum(1)\n",
        "        squarred_distance_neg_c = (negative2 - negative3).pow(2).sum(1)\n",
        "\n",
        "\n",
        "        quintuplet_loss = \\\n",
        "            F.relu(self.margin1 + squarred_distance_pos - squarred_distance_neg) \\\n",
        "            + F.relu(self.margin2 + squarred_distance_pos - squarred_distance_neg_b) \\\n",
        "            + F.relu(self.margin3 + squarred_distance_pos - squarred_distance_neg_c) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        return quintuplet_loss.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP5hv6i1u5yW",
        "outputId": "15291593-5be9-4973-cc07-e43eff0f21fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/weets\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/weets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDKp8Fk4OtsM"
      },
      "source": [
        "start training only with the loaded wieghts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4jI0mqebVTq",
        "outputId": "6ec22e68-e8c8-4963-8eaf-b2ab0e2f5d0d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "net = quintuplet().cuda()\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.0004)\n",
        "criterion = Quintupletloss()\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min',0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7bz8o__2JKn",
        "outputId": "3ccc436a-916b-47e7-85d5-7c3eb435d871"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "average last 10 iterations =  247.59681091308593\n",
            "average last 10 iterations =  169.01825103759765\n"
          ]
        }
      ],
      "source": [
        "countert = []\n",
        "counterv = []\n",
        "loss_historytrain = [] \n",
        "loss_historyvalid = [] \n",
        "iteration_numbert= 0\n",
        "iteration_numbertt= 0\n",
        "\n",
        "loss_train_items =[]\n",
        "\n",
        "epochh = 0\n",
        "epochhh = []\n",
        "\n",
        "min_valid_loss = 0.05\n",
        "\n",
        "# Iterate throught the epochs\n",
        "for epoch in range(60):\n",
        "    net.train()\n",
        "    train_loss = 0.0\n",
        "    epochh +=1\n",
        "    epochhh.append(epoch)\n",
        "    # Iterate over batches\n",
        "    epochh += 1\n",
        "    for i, (img0, img1, img2, img3, img4) in enumerate(trainloader,0):\n",
        "\n",
        "        # Send the images to CUDA\n",
        "        img0, img1, img2, img3, img4 = img0.cuda(), img1.cuda(), img2.cuda(), img3.cuda(), img4.cuda()\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "      \n",
        "        # Pass in the three images into the network \n",
        "        output1, output2, output3, output4, output5= net(img0, img1, img2, img3, img4)\n",
        "\n",
        "        # Pass the outputs into the loss function\n",
        "        loss_siamese = criterion(output1, output2, output3, output4, output5)\n",
        "\n",
        "        # Calculate the backpropagation\n",
        "        loss_siamese.backward()\n",
        "\n",
        "        # Optimize\n",
        "        optimizer.step()\n",
        "\n",
        "        # Every 10 batch print out the loss\n",
        "        \n",
        "        train_loss += loss_siamese.item()\n",
        "        \n",
        "        \n",
        "\n",
        "        \n",
        "        loss_train_items.append(loss_siamese.item())\n",
        "        if i % 10 == 0 and i>0:\n",
        "          average = sum(loss_train_items[-9:]) / 10\n",
        "          print('average last 10 iterations = ', sum(loss_train_items[-9:]) / 10)\n",
        "\n",
        "    \n",
        "    epoch_loss = (train_loss /len(trainloader))\n",
        "    loss_historytrain.append(epoch_loss)\n",
        "    print('average loss epoch =', (train_loss /len(trainloader)))\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    valid_loss= 0.0\n",
        "    # Iterate over batches\n",
        "    with torch.no_grad():\n",
        "      for i, (img0, img1, img2, img3, img4) in enumerate(validloader,0):\n",
        "\n",
        "          # Send the images to CUDA\n",
        "          img0, img1, img2, img3, img4 = img0.cuda(), img1.cuda(), img2.cuda(), img3.cuda(), img4.cuda()\n",
        "\n",
        "        \n",
        "          # Pass in the three images into the network \n",
        "          output1, output2, output3, output4, output5= net(img0, img1, img2, img3, img4)\n",
        "\n",
        "          # Pass the outputs into the loss function\n",
        "          loss_valid = criterion(output1, output2, output3, output4, output5)\n",
        "\n",
        "          # Every 10 batch print out the loss\n",
        "          \n",
        "          valid_loss += loss_valid.item()\n",
        "                   \n",
        "\n",
        "   \n",
        "            \n",
        "  \n",
        "      print('average valid loss epoch =', (valid_loss /len(validloader)))\n",
        "      average_valid_loss = valid_loss /len(validloader)\n",
        "      loss_historyvalid.append(average_valid_loss)\n",
        "      scheduler.step(average_valid_loss)\n",
        "      if min_valid_loss > average_valid_loss:\n",
        "          print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{average_valid_loss:.6f}) \\t Saving The Model')\n",
        "          min_valid_loss = average_valid_loss\n",
        "          # Saving State Dict\n",
        "          torch.save({\n",
        "            'model_state_dict': net.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            }, \n",
        "           'quinvalid33')\n",
        "\n",
        "     \n",
        "      \n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "show_plot(epochhh,loss_historytrain)\n",
        "show_plot(epochhh,loss_historyvalid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a14UZZ_2oeU"
      },
      "outputs": [],
      "source": [
        "#save the data as a checkpoint\n",
        "torch.save({\n",
        "            'model_state_dict': net.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            }, \n",
        "           'quinvalid3')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "5lossvalid",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}