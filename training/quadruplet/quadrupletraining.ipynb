{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFLiEonUv5cv"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import PIL.ImageOps    \n",
        "from torchvision import models, transforms\n",
        "import logging\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchvision.utils\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "import shutil\n",
        "import os\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8uJHLsgK-l-"
      },
      "outputs": [],
      "source": [
        "#for Plotting data\n",
        "def show_plot(iteration,loss):\n",
        "    plt.plot(iteration,loss)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr3WDlcSbSNJ"
      },
      "source": [
        "Bedoeling hieronder is dat ie uit de dataset random een pair pakt (img0 en img1) en eentje pakt die niet tot dezelfde class behoort\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yTBjtWl4jrV"
      },
      "outputs": [],
      "source": [
        "#dataloader for getting triplets from dataset\n",
        "class SiameseNetworkDataset(Dataset):\n",
        "    def __init__(self,imageFolderDataset,transform=None):\n",
        "        self.imageFolderDataset = imageFolderDataset    \n",
        "        self.transform = transform\n",
        "        \n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "        # img0_tuple = self.imageFolderDataset.imgs[index]\n",
        "\n",
        "        while True:\n",
        "          img1_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "          if img0_tuple[1] == img1_tuple[1]:\n",
        "            break\n",
        "        while True:\n",
        "          #search until they arent the same class\n",
        "          img2_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "          if img0_tuple[1] != img2_tuple[1]:\n",
        "            break\n",
        "        while True:\n",
        "          img3_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "          if (img3_tuple[1] != img1_tuple[1]) and (img3_tuple[1] != img2_tuple[1]):\n",
        "            break\n",
        "        \n",
        "        \n",
        "        img0 = Image.open(img0_tuple[0])\n",
        "        img1 = Image.open(img1_tuple[0])\n",
        "        img2 = Image.open(img2_tuple[0])\n",
        "        img3 = Image.open(img3_tuple[0])\n",
        "\n",
        "      \n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "            img3 = self.transform(img3)\n",
        "\n",
        "\n",
        "        return img0, img1, img2, img3\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.imageFolderDataset.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXeqpMD-JMxI",
        "outputId": "d11042d7-1cf1-4981-b025-09db9b86f83d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_gu-w-w1T8x"
      },
      "outputs": [],
      "source": [
        "# Resize the images and transform to tensors\n",
        "transformation = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(), transforms.Normalize(mean=[0.486, 0.459, 0.408],\n",
        "                                 std=[0.229, 0.224, 0.225]),\n",
        "                                    \n",
        "                                    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dAqFAwBmJRDI"
      },
      "outputs": [],
      "source": [
        "#directories of the MARKET-1501 data\n",
        "folder_dataset = datasets.ImageFolder(root=\"/content/drive/MyDrive/Person_reID_baseline_pytorch/Market-1501-v15.09.15/pytorch/train_all\")\n",
        "folder_validationset = datasets.ImageFolder(root=\"//content/drive/MyDrive/Person_reID_baseline_pytorch/Market-1501-v15.09.15/pytorch/valid\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6BLgqJQN1ylJ"
      },
      "outputs": [],
      "source": [
        "train = SiameseNetworkDataset(imageFolderDataset=folder_dataset,\n",
        "                                        transform=transformation)\n",
        "\n",
        "valid = SiameseNetworkDataset(imageFolderDataset=folder_validationset,\n",
        "                                        transform=transformation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RYsnMoWyIn7s"
      },
      "outputs": [],
      "source": [
        "trainloader = DataLoader(train, batch_size=32, num_workers=0, shuffle=True)\n",
        "validloader = DataLoader(valid, batch_size=32, num_workers=0, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v7XL7pCac-TW"
      },
      "outputs": [],
      "source": [
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wtceyuf7a1X5"
      },
      "outputs": [],
      "source": [
        "class Quadrupletv2(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Quadrupletv2, self).__init__()\n",
        "        self.net = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights)\n",
        "\n",
        "\n",
        "    def forward(self, input1, input2, input3, input4):\n",
        "\n",
        "        output1 = self.net(input1)\n",
        "        output2 = self.net(input2)\n",
        "        output3 = self.net(input3)\n",
        "        output4 = self.net(input4)\n",
        "\n",
        "        return output1, output2, output3, output4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rax388M10tm6"
      },
      "outputs": [],
      "source": [
        "# define the tripletLoss function\n",
        "class QuadrupletLoss(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Quadruplet loss function.\n",
        "    Ttakes 4 data point as input: one anchor, one positive and two negative examples. The negative examples needs not to be matching the anchor, the positive and each other.\n",
        "    the margins adds a minimal distance the model has to find between the images, instead of just >=0\n",
        "    \"\"\"\n",
        "    def __init__(self, margin1=1.0, margin2=0.25):\n",
        "        super(QuadrupletLoss, self).__init__()\n",
        "        self.margin1 = margin1\n",
        "        self.margin2 = margin2\n",
        "\n",
        "    def forward(self, anchor, positive, negative1, negative2):\n",
        "\n",
        "        squarred_distance_pos = (anchor - positive).pow(2).sum(1)\n",
        "        squarred_distance_neg = (anchor - negative1).pow(2).sum(1)\n",
        "        squarred_distance_neg_b = (negative1 - negative2).pow(2).sum(1)\n",
        "\n",
        "        quadruplet_loss = \\\n",
        "            F.relu(self.margin1 + squarred_distance_pos - squarred_distance_neg) \\\n",
        "            + F.relu(self.margin2 + squarred_distance_pos - squarred_distance_neg_b)\n",
        "\n",
        "        return quadruplet_loss.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XP5hv6i1u5yW",
        "outputId": "a542c1af-4f53-4e81-b524-ce0c16f44cea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/weets\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/weets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDKp8Fk4OtsM"
      },
      "source": [
        "start training only with the loaded wieghts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4jI0mqebVTq",
        "outputId": "b5c93c50-99fb-45ac-b265-c155ce58db6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "net = Quadrupletv2().cuda()\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.0004)\n",
        "criterion = QuadrupletLoss()\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min',0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U7bz8o__2JKn"
      },
      "outputs": [],
      "source": [
        "countert = []\n",
        "counterv = []\n",
        "loss_historytrain = [] \n",
        "loss_historyvalid = [] \n",
        "iteration_numbert= 0\n",
        "iteration_numbertt= 0\n",
        "\n",
        "loss_train_items =[]\n",
        "\n",
        "epochh = 0\n",
        "epochhh = []\n",
        "\n",
        "min_valid_loss = 100\n",
        "\n",
        "# Iterate throught the epochs\n",
        "for epoch in range(60):\n",
        "    net.train()\n",
        "    train_loss = 0.0\n",
        "    epochh +=1\n",
        "    epochhh.append(epoch)\n",
        "    # Iterate over batches\n",
        "    epochh += 1\n",
        "    for i, (img0, img1, img2, img3) in enumerate(trainloader,0):\n",
        "\n",
        "        # Send the images to CUDA\n",
        "        img0, img1, img2, img3 = img0.cuda(), img1.cuda(), img2.cuda(), img3.cuda()\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "      \n",
        "        # Pass in the three images into the network \n",
        "        output1, output2, output3, output4= net(img0, img1, img2, img3)\n",
        "\n",
        "        # Pass the outputs into the loss function\n",
        "        loss_siamese = criterion(output1, output2, output3, output4)\n",
        "\n",
        "        # Calculate the backpropagation\n",
        "        loss_siamese.backward()\n",
        "\n",
        "        # Optimize\n",
        "        optimizer.step()\n",
        "\n",
        "        # Every 10 batch print out the loss\n",
        "        \n",
        "        train_loss += loss_siamese.item()\n",
        "        \n",
        "        \n",
        "\n",
        "        \n",
        "        loss_train_items.append(loss_siamese.item())\n",
        "        if i % 10 == 0 and i>0:\n",
        "          average = sum(loss_train_items[-9:]) / 10\n",
        "          print('average last 10 iterations = ', sum(loss_train_items[-9:]) / 10)\n",
        "\n",
        "    \n",
        "    epoch_loss = (train_loss /len(trainloader))\n",
        "    loss_historytrain.append(epoch_loss)\n",
        "    print('average loss epoch =', (train_loss /len(trainloader)))\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    valid_loss= 0.0\n",
        "    # Iterate over batches\n",
        "    with torch.no_grad():\n",
        "      for i, (img0, img1, img2, img3) in enumerate(validloader,0):\n",
        "\n",
        "          # Send the images to CUDA\n",
        "          img0, img1, img2, img3 = img0.cuda(), img1.cuda(), img2.cuda(), img3.cuda()\n",
        "\n",
        "        \n",
        "          # Pass in the three images into the network \n",
        "          output1, output2, output3, output4= net(img0, img1, img2, img3)\n",
        "\n",
        "          # Pass the outputs into the loss function\n",
        "          loss_valid = criterion(output1, output2, output3, output4)\n",
        "\n",
        "          # Every 10 batch print out the loss\n",
        "          \n",
        "          valid_loss += loss_valid.item()\n",
        "                   \n",
        "\n",
        "   \n",
        "            \n",
        "  \n",
        "      print('average valid loss epoch =', (valid_loss /len(validloader)))\n",
        "      average_valid_loss = valid_loss /len(validloader)\n",
        "      loss_historyvalid.append(average_valid_loss)\n",
        "      scheduler.step(average_valid_loss)\n",
        "      if min_valid_loss > average_valid_loss:\n",
        "          print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{average_valid_loss:.6f}) \\t Saving The Model')\n",
        "          min_valid_loss = average_valid_loss\n",
        "          # Saving State Dict\n",
        "          torch.save({\n",
        "            'model_state_dict': net.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            }, \n",
        "           'quadruplet1501V2validschedulegrafiek')\n",
        "\n",
        "     \n",
        "      \n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "show_plot(epochhh,loss_historytrain)\n",
        "show_plot(epochhh,loss_historyvalid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFUdxZXSq3q9"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/weets"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Quadrupvalidloss",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}