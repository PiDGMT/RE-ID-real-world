{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFLiEonUv5cv"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import PIL.ImageOps    \n",
        "from torchvision import models, transforms\n",
        "import logging\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchvision.utils\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "import shutil\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8uJHLsgK-l-"
      },
      "outputs": [],
      "source": [
        "#for Plotting training graphs\n",
        "def show_plot(iteration,loss):\n",
        "    plt.plot(iteration,loss)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr3WDlcSbSNJ"
      },
      "source": [
        "Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yTBjtWl4jrV"
      },
      "outputs": [],
      "source": [
        "#dataloader for getting triplets from dataset\n",
        "class SiameseNetworkDataset(Dataset):\n",
        "    def __init__(self,imageFolderDataset,transform=None):\n",
        "        self.imageFolderDataset = imageFolderDataset    \n",
        "        self.transform = transform\n",
        "        \n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "\n",
        "        #search until requirements are met (same class)\n",
        "        while True:\n",
        "          img1_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "          if img0_tuple[1] == img1_tuple[1]:\n",
        "            break\n",
        "        while True:\n",
        "          #search until they arent the same class\n",
        "          img2_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "          if img0_tuple[1] != img2_tuple[1]:\n",
        "            break\n",
        "        \n",
        "        \n",
        "        img0 = Image.open(img0_tuple[0])\n",
        "        img1 = Image.open(img1_tuple[0])\n",
        "        img2 = Image.open(img2_tuple[0])\n",
        "\n",
        "      \n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "\n",
        "\n",
        "        return img0, img1, img2\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.imageFolderDataset.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXeqpMD-JMxI",
        "outputId": "ef3c295e-0a59-4469-8292-3903c53cd836"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformations"
      ],
      "metadata": {
        "id": "TzShM53ydZfy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_gu-w-w1T8x"
      },
      "outputs": [],
      "source": [
        "# Resize the images and transform to tensors\n",
        "transformation = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(), transforms.Normalize(mean=[0.486, 0.459, 0.408],\n",
        "                                 std=[0.229, 0.224, 0.225]),\n",
        "                                    \n",
        "                                    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAqFAwBmJRDI"
      },
      "outputs": [],
      "source": [
        "folder_dataset = datasets.ImageFolder(root=\"/content/drive/MyDrive/Person_reID_baseline_pytorch/Market-1501-v15.09.15/pytorch/train_all\")\n",
        "folder_validationset = datasets.ImageFolder(root=\"//content/drive/MyDrive/Person_reID_baseline_pytorch/Market-1501-v15.09.15/pytorch/valid\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BLgqJQN1ylJ"
      },
      "outputs": [],
      "source": [
        "train = SiameseNetworkDataset(imageFolderDataset=folder_dataset,\n",
        "                                        transform=transformation)\n",
        "\n",
        "valid = SiameseNetworkDataset(imageFolderDataset=folder_validationset,\n",
        "                                        transform=transformation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYsnMoWyIn7s"
      },
      "outputs": [],
      "source": [
        "trainloader = DataLoader(train, batch_size=32, num_workers=0, shuffle=True)\n",
        "validloader = DataLoader(valid, batch_size=32, num_workers=0, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7XL7pCac-TW"
      },
      "outputs": [],
      "source": [
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtceyuf7a1X5"
      },
      "outputs": [],
      "source": [
        "from torchvision.models.efficientnet import efficientnet_b1\n",
        "class Tripletb1(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Tripletb1, self).__init__()\n",
        "        self.net = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights)\n",
        "\n",
        "    def forward(self, input1, input2, input3):\n",
        "\n",
        "        output1 = self.net(input1)\n",
        "        output2 = self.net(input2)\n",
        "        output3 = self.net(input3)\n",
        "\n",
        "        return output1, output2, output3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rax388M10tm6"
      },
      "outputs": [],
      "source": [
        "# define the tripletLoss function\n",
        "class TripletLoss(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Quadruplet loss function.\n",
        "    Builds on the Triplet Loss and takes 4 data input: one anchor, one positive and two negative examples. The negative examples needs not to be matching the anchor, the positive and each other.\n",
        "    the margins adds a minimal distance the model has to find between the images, instead of just >0\n",
        "    \"\"\"\n",
        "    def __init__(self, margin1=1):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin1 = margin1\n",
        "\n",
        "    def forward(self, anchor, positive, negative1):\n",
        "\n",
        "        squarred_distance_pos = (anchor - positive).pow(2).sum(1)\n",
        "        squarred_distance_neg = (anchor - negative1).pow(2).sum(1)\n",
        "\n",
        "        tripletloss = \\\n",
        "            F.relu(self.margin1 + squarred_distance_pos - squarred_distance_neg) \n",
        "\n",
        "        return tripletloss.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDKp8Fk4OtsM"
      },
      "source": [
        "start training only with the loaded wieghts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4jI0mqebVTq"
      },
      "outputs": [],
      "source": [
        "net = Tripletb1().cuda()\n",
        "criterion = TripletLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.0004)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min',0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBTG1D3EOmaD"
      },
      "source": [
        "Load the checkpoints to resume training if halted\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U7bz8o__2JKn"
      },
      "outputs": [],
      "source": [
        "loss_historytrain = [] \n",
        "loss_historyvalid = [] \n",
        "loss_train_items =[]\n",
        "\n",
        "min_valid_loss = 100\n",
        "epochs = []\n",
        "\n",
        "# Iterate throught the epochs\n",
        "for epoch in range(60):\n",
        "    torch.cuda.empty_cache()\n",
        "    net.train()\n",
        "    train_loss = 0.0\n",
        "    epochs.append(epoch)\n",
        "    # Iterate over batches\n",
        "    for i, (img0, img1, img2) in enumerate(trainloader,0):\n",
        "\n",
        "        # Send the images to CUDA\n",
        "        img0, img1, img2 = img0.cuda(), img1.cuda(), img2.cuda()\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "      \n",
        "        # Pass in the three images into the network \n",
        "        output1, output2, output3= net(img0, img1, img2)\n",
        "\n",
        "        # Pass the outputs into the loss function\n",
        "        loss_siamese = criterion(output1, output2, output3)\n",
        "\n",
        "        # Calculate the backpropagation\n",
        "        loss_siamese.backward()\n",
        "\n",
        "        # Optimize\n",
        "        optimizer.step()\n",
        "\n",
        "        # add the loss to the total\n",
        "        \n",
        "        train_loss += loss_siamese.item()\n",
        "        \n",
        "        \n",
        "\n",
        "        \n",
        "        loss_train_items.append(loss_siamese.item())\n",
        "        if i % 10 == 0 and i>0:\n",
        "          average = sum(loss_train_items[-9:]) / 10\n",
        "          print('average last 10 iterations = ', sum(loss_train_items[-9:]) / 10)\n",
        "\n",
        "    \n",
        "    epoch_loss = (train_loss /len(trainloader))\n",
        "    loss_historytrain.append(float(epoch_loss))\n",
        "    print('average loss epoch =', (train_loss /len(trainloader)))\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    valid_loss= 0.0\n",
        "    # Iterate over batches\n",
        "    with torch.no_grad():\n",
        "      net.eval()\n",
        "      for i, (img0, img1, img2) in enumerate(validloader,0):\n",
        "\n",
        "          # Send the images to CUDA\n",
        "          img0, img1, img2 = img0.cuda(), img1.cuda(), img2.cuda()\n",
        "\n",
        "        \n",
        "          # Pass in the three images into the network \n",
        "          output1, output2, output3= net(img0, img1, img2)\n",
        "\n",
        "          # Pass the outputs into the loss function\n",
        "          loss_valid = criterion(output1, output2, output3)\n",
        "\n",
        "          # Every 10 batch print out the loss\n",
        "          \n",
        "          valid_loss += loss_valid.item()\n",
        "\n",
        "          \n",
        "                  \n",
        "\n",
        "   \n",
        "            \n",
        "  \n",
        "      print('average valid loss epoch =', (valid_loss /len(validloader)))\n",
        "      average_valid_loss = valid_loss /len(validloader)\n",
        "      loss_historyvalid.append(float(average_valid_loss))\n",
        "      scheduler.step(average_valid_loss)\n",
        "      if min_valid_loss > average_valid_loss:\n",
        "          print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{average_valid_loss:.6f}) \\t Saving The Model')\n",
        "          min_valid_loss = average_valid_loss\n",
        "          # Saving State Dict\n",
        "          torch.save({\n",
        "            'model_state_dict': net.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            }, \n",
        "           'triplet1501V2validb1schedule')\n",
        "\n",
        "     \n",
        "      \n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "show_plot(epochs,loss_historytrain)\n",
        "show_plot(epochs,loss_historyvalid)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "tripletlossVALID",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
