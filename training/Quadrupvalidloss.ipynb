{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OFLiEonUv5cv"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import PIL.ImageOps    \n",
        "from torchvision import models, transforms\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchvision.utils\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "import shutil\n",
        "import os\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "B8uJHLsgK-l-"
      },
      "outputs": [],
      "source": [
        "#plot function for training graphs\n",
        "def show_plot(iteration,loss):\n",
        "    plt.plot(iteration,loss)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr3WDlcSbSNJ"
      },
      "source": [
        "Dataloader for images from the dataset\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5yTBjtWl4jrV"
      },
      "outputs": [],
      "source": [
        "#dataloader for getting triplets from dataset\n",
        "class SiameseNetworkDataset(Dataset):\n",
        "    def __init__(self,imageFolderDataset,transform=None):\n",
        "        self.imageFolderDataset = imageFolderDataset    \n",
        "        self.transform = transform\n",
        "        \n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "\n",
        "        while True:\n",
        "          img1_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "          if img0_tuple[1] == img1_tuple[1]:\n",
        "            break\n",
        "        while True:\n",
        "          #search until they arent the same class\n",
        "          img2_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "          if img0_tuple[1] != img2_tuple[1]:\n",
        "            break\n",
        "        while True:\n",
        "          img3_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "          if (img3_tuple[1] != img1_tuple[1]) and (img3_tuple[1] != img2_tuple[1]):\n",
        "            break\n",
        "        \n",
        "        \n",
        "        img0 = Image.open(img0_tuple[0])\n",
        "        img1 = Image.open(img1_tuple[0])\n",
        "        img2 = Image.open(img2_tuple[0])\n",
        "        img3 = Image.open(img3_tuple[0])\n",
        "\n",
        "      \n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "            img3 = self.transform(img3)\n",
        "\n",
        "\n",
        "        return img0, img1, img2, img3\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.imageFolderDataset.imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link to (personal) google drive where the dataset is stored"
      ],
      "metadata": {
        "id": "4ikE9f5jQYMa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXeqpMD-JMxI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformation\n"
      ],
      "metadata": {
        "id": "c7zHH3NkEEXc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "F_gu-w-w1T8x"
      },
      "outputs": [],
      "source": [
        "# Resize the images and transform to tensors\n",
        "transformation = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(), transforms.Normalize(mean=[0.486, 0.459, 0.408],\n",
        "                                 std=[0.229, 0.224, 0.225]),\n",
        "                                    \n",
        "                                    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dAqFAwBmJRDI"
      },
      "outputs": [],
      "source": [
        "#directories of the MARKET-1501 data\n",
        "folder_dataset = datasets.ImageFolder(root=\"/content/drive/MyDrive/Person_reID_baseline_pytorch/Market-1501-v15.09.15/pytorch/train_all\")\n",
        "folder_validationset = datasets.ImageFolder(root=\"//content/drive/MyDrive/Person_reID_baseline_pytorch/Market-1501-v15.09.15/pytorch/valid\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6BLgqJQN1ylJ"
      },
      "outputs": [],
      "source": [
        "train = SiameseNetworkDataset(imageFolderDataset=folder_dataset,\n",
        "                                        transform=transformation)\n",
        "\n",
        "valid = SiameseNetworkDataset(imageFolderDataset=folder_validationset,\n",
        "                                        transform=transformation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RYsnMoWyIn7s"
      },
      "outputs": [],
      "source": [
        "trainloader = DataLoader(train, batch_size=32, num_workers=0, shuffle=True)\n",
        "validloader = DataLoader(valid, batch_size=32, num_workers=0, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "v7XL7pCac-TW"
      },
      "outputs": [],
      "source": [
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wtceyuf7a1X5"
      },
      "outputs": [],
      "source": [
        "class Quadrupletv2(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Quadrupletv2, self).__init__()\n",
        "        self.net = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights)\n",
        "\n",
        "\n",
        "    def forward(self, input1, input2, input3, input4):\n",
        "\n",
        "        output1 = self.net(input1)\n",
        "        output2 = self.net(input2)\n",
        "        output3 = self.net(input3)\n",
        "        output4 = self.net(input4)\n",
        "\n",
        "        return output1, output2, output3, output4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rax388M10tm6"
      },
      "outputs": [],
      "source": [
        "# define the tripletLoss function\n",
        "class QuadrupletLoss(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Quadruplet loss function.\n",
        "    Ttakes 4 data point as input: one anchor, one positive and two negative examples. The negative examples needs not to be matching the anchor, the positive and each other.\n",
        "    the margins adds a minimal distance the model has to find between the images, instead of just >=0\n",
        "    \"\"\"\n",
        "    def __init__(self, margin1=1.0, margin2=0.25):\n",
        "        super(QuadrupletLoss, self).__init__()\n",
        "        self.margin1 = margin1\n",
        "        self.margin2 = margin2\n",
        "\n",
        "    def forward(self, anchor, positive, negative1, negative2):\n",
        "\n",
        "        squarred_distance_pos = (anchor - positive).pow(2).sum(1)\n",
        "        squarred_distance_neg = (anchor - negative1).pow(2).sum(1)\n",
        "        squarred_distance_neg_b = (negative1 - negative2).pow(2).sum(1)\n",
        "\n",
        "        quadruplet_loss = \\\n",
        "            F.relu(self.margin1 + squarred_distance_pos - squarred_distance_neg) \\\n",
        "            + F.relu(self.margin2 + squarred_distance_pos - squarred_distance_neg_b)\n",
        "\n",
        "        return quadruplet_loss.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDKp8Fk4OtsM"
      },
      "source": [
        "start training only with the loaded wieghts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4jI0mqebVTq"
      },
      "outputs": [],
      "source": [
        "net = Quadrupletv2().cuda()\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.0004)\n",
        "criterion = QuadrupletLoss()\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min',0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7bz8o__2JKn"
      },
      "outputs": [],
      "source": [
        "loss_historytrain = [] \n",
        "loss_historyvalid = [] \n",
        "loss_train_items =[]\n",
        "\n",
        "epochs = []\n",
        "\n",
        "min_valid_loss = 100\n",
        "\n",
        "# Iterate throught the epochs\n",
        "for epoch in range(60):\n",
        "    net.train()\n",
        "    train_loss = 0.0\n",
        "    epochs.append(epoch)\n",
        "    # Iterate over batches\n",
        "    for i, (img0, img1, img2, img3) in enumerate(trainloader,0):\n",
        "\n",
        "        # Send the images to CUDA\n",
        "        img0, img1, img2, img3 = img0.cuda(), img1.cuda(), img2.cuda(), img3.cuda()\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "      \n",
        "        # Pass in the three images into the network \n",
        "        output1, output2, output3, output4= net(img0, img1, img2, img3)\n",
        "\n",
        "        # Pass the outputs into the loss function\n",
        "        loss_siamese = criterion(output1, output2, output3, output4)\n",
        "\n",
        "        # Calculate the backpropagation\n",
        "        loss_siamese.backward()\n",
        "\n",
        "        # Optimize\n",
        "        optimizer.step()\n",
        "\n",
        "        # add the loss to the total\n",
        "        train_loss += loss_siamese.item()\n",
        "        \n",
        "        \n",
        "\n",
        "        \n",
        "        loss_train_items.append(loss_siamese.item())\n",
        "        if i % 10 == 0 and i>0:\n",
        "          average = sum(loss_train_items[-9:]) / 10\n",
        "          print('average last 10 iterations = ', sum(loss_train_items[-9:]) / 10)\n",
        "\n",
        "    \n",
        "    epoch_loss = (train_loss /len(trainloader))\n",
        "    loss_historytrain.append(epoch_loss)\n",
        "    print('average loss epoch =', (train_loss /len(trainloader)))\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    valid_loss= 0.0\n",
        "    # Iterate over batches\n",
        "    with torch.no_grad():\n",
        "      net.eval()\n",
        "      for i, (img0, img1, img2, img3) in enumerate(validloader,0):\n",
        "\n",
        "          # Send the images to CUDA\n",
        "          img0, img1, img2, img3 = img0.cuda(), img1.cuda(), img2.cuda(), img3.cuda()\n",
        "\n",
        "        \n",
        "          # Pass in the three images into the network \n",
        "          output1, output2, output3, output4= net(img0, img1, img2, img3)\n",
        "\n",
        "          # Pass the outputs into the loss function\n",
        "          loss_valid = criterion(output1, output2, output3, output4)\n",
        "\n",
        "          # add the loss to the total\n",
        "          valid_loss += loss_valid.item()\n",
        "                   \n",
        "\n",
        "   \n",
        "            \n",
        "  \n",
        "      print('average valid loss epoch =', (valid_loss /len(validloader)))\n",
        "      average_valid_loss = valid_loss /len(validloader)\n",
        "      loss_historyvalid.append(average_valid_loss)\n",
        "      scheduler.step(average_valid_loss)\n",
        "      if min_valid_loss > average_valid_loss:\n",
        "          print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{average_valid_loss:.6f}) \\t Saving The Model')\n",
        "          min_valid_loss = average_valid_loss\n",
        "          # Saving State Dict\n",
        "          torch.save({\n",
        "            'model_state_dict': net.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            }, \n",
        "           'quadruplet1501V2resnet5ddd0')\n",
        "\n",
        "     \n",
        "      \n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "show_plot(epochs,loss_historytrain)\n",
        "show_plot(epochs,loss_historyvalid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFUdxZXSq3q9"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/weets"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Quadrupvalidloss",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}